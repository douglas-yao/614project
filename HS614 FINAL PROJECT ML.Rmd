---
title: "HS614 Final Project RMD"
output:
  pdf_document: default
  html_document: default
  word_document: default
---

```{r}
#Read data & turn blank & ? into NA strings
diabeticdata <- read.csv("~/Desktop/diabetic_data.csv", na.strings = c("?", "NA"))
summary(diabeticdata)
str(diabeticdata)
```

```{r}
#Install and load libraries
require(caret)
require(lattice)
require(randomForest)
require(dplyr)
require(e1071)
require(ggplot2)
require(pROC)
require(ROCR)
require(ROSE)
require(ranger)
require(stringr)
require(rebus)
require(klaR)
require(Rmisc)
require(plyr)
require(RColorBrewer)
require(factoextra)
require(car)
require(cluster)
```

```{r}
###CLEAN THE DATA###
#Remove unapplicable columns
colnames(diabeticdata)
mydiabeticdata <- subset(diabeticdata, select = -c(weight, encounter_id, patient_nbr, payer_code, medical_specialty, examide, citoglipton, metformin.rosiglitazone, glipizide.metformin, glimepiride.pioglitazone, metformin.pioglitazone, acetohexamide, diag_2, diag_3))
```

```{r}
#Renaming Values
#Change readmitted classes >30 <30 to YES
levels(mydiabeticdata$readmitted) <- c("Yes", "Yes", "No")

#Classify ICD codes as DX catagories
mydiabeticdata$diag_1 <- as.character(mydiabeticdata$diag_1)
mydiabeticdata$diag_1[str_detect(mydiabeticdata$diag_1, pattern = START %R% or("39","40","41","42","43","44","45","785")) == T] <- "Circulatory"
mydiabeticdata$diag_1[str_detect(mydiabeticdata$diag_1, pattern = START %R% or("52","53","54","55","56","57","787")) == T] <- "Digestive"
mydiabeticdata$diag_1[str_detect(mydiabeticdata$diag_1, pattern = START %R% or("58","59","60","61","62","788")) == T] <- "Genitourinary"
mydiabeticdata$diag_1[str_detect(mydiabeticdata$diag_1, pattern = START %R% "25") == T] <- "Diabetes"
mydiabeticdata$diag_1[str_detect(mydiabeticdata$diag_1, pattern = START %R% or("80","81","82","83","84","85",
                                                               "86","87","88","89","90","91",
                                                               "92","93","94","95","96","97",
                                                               "98","99")) == T] <- "Injury"
mydiabeticdata$diag_1[str_detect(mydiabeticdata$diag_1, pattern = START %R% or("71","72","73")) == T] <- "Musculoskeletal"
mydiabeticdata$diag_1[str_detect(mydiabeticdata$diag_1, pattern = START %R% or("14","15","16","17","18","19",
                                                               "20","21","22","23")) == T] <- "Neoplasms"
mydiabeticdata$diag_1[str_detect(mydiabeticdata$diag_1, pattern = START %R% or("46","47","48","49","50","51","786")) == T] <- "Respiratory"
mydiabeticdata$diag_1[str_detect(mydiabeticdata$diag_1, pattern = "[[:digit:]]") == T] <- "Other"
mydiabeticdata$diag_1 <- as.factor(mydiabeticdata$diag_1)
plot(mydiabeticdata$diag_1)

#Classify Admission Type ID
mydiabeticdata$admission_type_id <- as.character(mydiabeticdata$admission_type_id)
mydiabeticdata$admission_type_id[mydiabeticdata$admission_type_id==1] <- 'Emergency'
mydiabeticdata$admission_type_id[mydiabeticdata$admission_type_id==2] <- 'Urgent'
mydiabeticdata$admission_type_id[mydiabeticdata$admission_type_id==3] <- 'Elective'
mydiabeticdata$admission_type_id[mydiabeticdata$admission_type_id==4] <- 'Newborn'
mydiabeticdata$admission_type_id[mydiabeticdata$admission_type_id==5] <- NA
mydiabeticdata$admission_type_id[mydiabeticdata$admission_type_id==6] <- NA
mydiabeticdata$admission_type_id[mydiabeticdata$admission_type_id==7] <- 'Trauma Center'
mydiabeticdata$admission_type_id[mydiabeticdata$admission_type_id==8] <- NA
mydiabeticdata$admission_type_id <- as.factor(mydiabeticdata$admission_type_id)
plot(mydiabeticdata$admission_type_id)

#Classify Admission Source ID
mydiabeticdata$admission_source_id <- as.character(mydiabeticdata$admission_source_id)
mydiabeticdata$admission_source_id <- recode(mydiabeticdata$admission_source_id, "c(1,2,3) = 'Refer'")
mydiabeticdata$admission_source_id <- recode(mydiabeticdata$admission_source_id, "c(4,5,6,10,18,19,22,25,26) = 'Transfer'")
mydiabeticdata$admission_source_id[mydiabeticdata$admission_source_id== '7'] <- 'ER'
mydiabeticdata$admission_source_id[mydiabeticdata$admission_source_id== '8'] <- 'Court'
mydiabeticdata$admission_source_id <- recode(mydiabeticdata$admission_source_id, "c(9,15,17,20,21) = 'Unknown'")
mydiabeticdata$admission_source_id <- recode(mydiabeticdata$admission_source_id, "c(11,12,13,14,23,24) = 'Pediatric'")
mydiabeticdata$admission_source_id <- as.factor(mydiabeticdata$admission_source_id)
plot(mydiabeticdata$admission_source_id)

#Classify Discharge 
mydiabeticdata$discharge_disposition_id <- as.character(mydiabeticdata$discharge_disposition_id)
mydiabeticdata$discharge_disposition_id[mydiabeticdata$discharge_disposition_id==1] <- 'Home'
mydiabeticdata$discharge_disposition_id <- recode(mydiabeticdata$discharge_disposition_id, "c('2','5','28')='Inpatient' ")
mydiabeticdata$discharge_disposition_id <- recode(mydiabeticdata$discharge_disposition_id, "c('3','4','16','17','22','23','24')='Outpatient' ")
mydiabeticdata$discharge_disposition_id <- recode(mydiabeticdata$discharge_disposition_id, "c('6','8')='Home Health' ")
mydiabeticdata$discharge_disposition_id <- recode(mydiabeticdata$discharge_disposition_id, "c('7')='AMA' ")
mydiabeticdata$discharge_disposition_id <- recode(mydiabeticdata$discharge_disposition_id, "c('11','19','20','21')='Expired' ")
mydiabeticdata$discharge_disposition_id <- recode(mydiabeticdata$discharge_disposition_id, "c('12','15')='Same Institute' ")
mydiabeticdata$discharge_disposition_id <- recode(mydiabeticdata$discharge_disposition_id, "c('13','14')='Hospice' ")
mydiabeticdata$discharge_disposition_id <- recode(mydiabeticdata$discharge_disposition_id, "c('27','29','30')='' ")
mydiabeticdata$discharge_disposition_id <- recode(mydiabeticdata$discharge_disposition_id, "c('9','10','18','25','26')= 'Unknown'")
mydiabeticdata$discharge_disposition_id <- recode(mydiabeticdata$discharge_disposition_id, "c('2','5','28')='Inpatient' ")
mydiabeticdata$discharge_disposition_id <- as.factor(mydiabeticdata$discharge_disposition_id)
plot(mydiabeticdata$discharge_disposition_id)

```

DATA ENGINEERING, FEATURE EXTRACTION, AND SELECTION
Goal: To predict readmission in diabetic patients based on data set (Class label: “Readmitted”) and to analyze the correlation of the extracted variables  and probability of being readmitted.

- I identified clinical features and demographics that contribute to diabetic care and potential outcomes that may lead to readmission.
- Deleted the following features: weight, encounter_id, patient_nbr, payer_code, medical_specialty, examide, citoglipton, metformin.rosiglitazone, glipizide.metformin, glimepiride.pioglitazone, metformin.pioglitazone, acetohexamide, diag_2, diag_3
- Encounter_id, patient_nbr, payer_code, medical specialty does not apply clinically to a patients probability of readmission
- Diag_2 and diag_3 are secondary and tertiary diagnosis and not the primary diagnosis (reason for admit). Although comorbidities may be applicable, we'll consider number_diagnoses column to account for this information.
- Weight had significant # of NAs, therefore deleted.
- Examide, citoglipton, metformin.rosiglitazone, glipizide.metformin, glimepiride.pioglitazone, metformin.pioglitazone, acetohexamide because either these had only 1 level or some contain classes with 1 or 2 data points, therefore there isn't enough variability if we were to split into training/test data sets. 

Issues: I discovered immediately was that race didn’t have much variability in the occurrences, specifically the significant amount of the Caucasian race compared to the rest. However, I didn’t delete eliminate this feature, otherwise we’d lose most of our data. This is just something I would consider when publishing and applying our model.      

```{r}
#Split Training and Testing data
set.seed(2)
ind <- sample(2, nrow(mydiabeticdata), replace=TRUE, prob = c(0.7,0.3))
diabetictrain <- mydiabeticdata[ind==1,]
diabetictest <- mydiabeticdata[ind==2,]

#Scaling
preProcValues <- preProcess(diabetictrain, method = c("center","scale"))
trainTransformed <- predict(preProcValues, diabetictrain)
testTransformed <- predict(preProcValues, diabetictest)

#Remove NA Values
trainTransformed  <- na.omit(trainTransformed)
testTransformed <- na.omit(testTransformed)
```


```{r}
###VISUALIZATION###
# GG Plot, using geom bar to create a bar chart since readmitted is a catogorical data
p1 <- ggplot(mydiabeticdata, aes(x = race, fill = readmitted)) +
  geom_bar() +
  theme_bw() +
  labs(x = "Race", y = "Patient Count", title = "Readmits by Race")

p2 <- ggplot(mydiabeticdata, aes(x = gender, fill = readmitted)) +
  geom_bar() +
  theme_bw() +
  labs(x = "Gender", y = "Patient Count", title = "Readmits by Gender")

p3 <- ggplot(mydiabeticdata, aes(x = age, fill = readmitted)) +
  geom_bar() +
  theme_bw() +
  labs(x = "Age", y = "Patient Count", title = "Readmits by Age")

p4 <- ggplot(mydiabeticdata, aes(x = diag_1, fill = readmitted)) +
  geom_bar() +
  theme_bw() +
  labs(x = "Diagnosis", y = "Patient Count", title = "Readmits by Diagnosis")

p5 <- ggplot(mydiabeticdata, aes(x = admission_type_id, fill = readmitted)) +
  geom_bar() +
  theme_bw() +
  labs(x = "Admission Type", y = "Patient Count", title = "Readmits by Admission Source")

p6 <- ggplot(mydiabeticdata, aes(x = admission_source_id, fill = readmitted)) +
  geom_bar() +
  theme_bw() +
  labs(x = "Admission Source", y = "Patient Count", title = "Readmits by Admission Source")

p7 <- ggplot(mydiabeticdata, aes(x = discharge_disposition_id, fill = readmitted)) +
  geom_bar() +
  theme_bw() +
  labs(x = "Discharge Disposition", y = "Patient Count", title = "Readmits by Discharge Disposition")

multiplot(p1, p2, p3, p4, p5, p6, p7, cols=3)

###Other Visualization
#bargraphs - readmit based on race
b1 <- readmitcounts <- table(mydiabeticdata$readmitted, mydiabeticdata$race)
barplot(readmitcounts, main="# of Hospital Readmits Based on Race", xlab="Race", col=c("blue","red"), legend = rownames(readmitcounts), beside=TRUE)

#bargraphs - readmit based on age
b2 <- readmitcounts <- table(mydiabeticdata$readmitted, mydiabeticdata$age)
barplot(readmitcounts, main="# of Hospital Readmits Based on Age", xlab="Age", col=c("blue","red"), legend = rownames(readmitcounts), beside=TRUE)

#bargraphs - readmit based on # of diagnoses
b3 <- readmitcounts <- table(mydiabeticdata$readmitted, mydiabeticdata$number_diagnoses)
barplot(readmitcounts, main="# of Hospital Readmits Based on # of Dx", xlab="# of Diagnoses", col=c("blue","red"), legend = rownames(readmitcounts), beside=TRUE)

#bargraphs - readmit based on outpatient visits
b4 <- readmitcounts <- table(mydiabeticdata$readmitted, mydiabeticdata$number_outpatient)
barplot(readmitcounts, main="# of Hospital Readmits Based on Outpatient Visits", xlab="# Outpatient Visits", col=c("blue","red"), legend = rownames(readmitcounts), beside=TRUE)

```

Data Exploration
I favored the idea of barplots in this context and separating out colors to quickly identify readmission versus no readmission. This clearly displays the various categorical features and compares the different classes that affect our dataset. The height of patient count quickly specifies the characteristics of our patient population. Some of the analysis I've obtained from these bar plots include :
1.) Significantly high number of caucasian patients compared to other racial background (geographic impact perhaps?)
2.) Circulatory diagnosis type for patients with diabetes (diabetic complications involve compromised circulatory conditions)
3.) # of patients and registratIncrease in age (highest patient population are 70-80 years old)
4.) Readmission type and source are related to emergency

```{r}
###CLUSTERING### - K-Means

#create new train dataframe with numeric variables - all dimensions 
mynumericdf <- subset(trainTransformed, select = c(time_in_hospital, num_lab_procedures, num_procedures, num_medications, number_outpatient, number_emergency, number_inpatient, number_diagnoses))

#Elbow method 
fviz_nbclust(mynumericdf, kmeans, method = "wss")

#Silhouette score
require(cluster)
k.max <- 15
sil <- rep(0, k.max)

# Compute the average silhouette width for 
# k = 2 to k = 5
for(i in 2:k.max){
  km.res <- kmeans(mynumericdf, centers = i, nstart = 25)
  ss <- silhouette(km.res$cluster, dist(mynumericdf))
  sil[i] <- mean(ss[, 3])
}

# Plot the  average silhouette width
plot(1:k.max, sil, type = "b", pch = 19, 
     frame = FALSE, xlab = "Number of clusters k")
abline(v = which.max(sil), lty = 2)

results <- kmeans(mynumericdf, centers = 3, nstart = 25)
print(results)

plot(mynumericdf, col=results$cluster)
points(mynumericdf$centers,col=1:2,pch=8,cex=1)
fviz_cluster(results, data = mynumericdf)

###CLUSTERING - Hierichal
Sample = sample(nrow(mynumericdf), 500)
dfdist <- dist(as.matrix(mynumericdf[Sample,]))
dfhclust <- hclust(dfdist, method="ward.D")
plot(dfhclust)
rect.hclust(hclust(dfdist, method="ward.D"),h=120)
```

CLUSTERING

I had originally chosen k=2 (2 clusters) because based on the class label we’re trying to predict, we had two options of “Yes” and “No”. I’m using the elbow method to assist in suggesting optimal # of clusters. I’m able to visually look at a scree plot and specify the point where rate of decline changes the most by locating the bend in the knee on the graph. In this case I'd select 3 clusters. I’ve also attempted to calculate the silhouette score to compute the average silhouette width between 2-15 instead of assuming 2. I've already scaled my data (see line 116). In regards to Clustering, I've subsetted features that contained quantitative data. Clustering with this particular Diabetes data set is a little more challenging such that that data supplied were mostly categorical, thus would not be able to measure distances unless we quantify this.

Metrics used:
Center = 2 (This is based off the optimal # of cluster)
nstart = 25 (25 is often the recommended #)
The Center will provide 2 clusters of data points to extract. K means will attempt multiple times and select the best run. Here, I’ve chosen 25 attempts (configurations), which is often recommended.
ward.D was a suggested hierichal method

In some cases, the data is cleanly clustered. In analyzing the plot graphs, lab procedures in particular in relation to other features seem to have distinct clusters. Note the clear cut separation (green, red, black).The 3 clusters do overlap, but still a bit clear to make the distinction between  them.

The characteristics of the visual data might suggest that there may be distinctions in the original class label (readmitted). Having 3 cluster can possibly imply that the characteristic of the data set could classify patients being readmitted “<30 days”, “>30 days”, and “No”. Keeping the original # of levels is something we can consider in approach different models. 

Sources:
http://www.sthda.com/english/wiki/print.php?id=239#r-codes-1
https://www.r-statistics.com/2013/08/k-means-clustering-from-r-in-action/

```{r}
#Histograms - Similar to above, but for numberical features

b1 <- ggplot(diabetictrain, aes(x = time_in_hospital, fill = readmitted)) +
  geom_bar() +
  theme_bw() +
  labs(x = "Time in Hospital", y = "Patient Count", title = "Readmits by Hospital Length of Stay")

b2 <- ggplot(diabetictrain, aes(x = num_lab_procedures, fill = readmitted)) +
  geom_bar() +
  theme_bw() +
  labs(x = "# of Lab Procedures", y = "Patient Count", title = "Readmits by # Lab Procedures")

b3 <- ggplot(diabetictrain, aes(x = num_procedures, fill = readmitted)) +
  geom_bar() +
  theme_bw() +
  labs(x = "# Procedures", y = "Patient Count", title = "Readmits by # Procedures")

b4 <- ggplot(diabetictrain, aes(x = num_medications, fill = readmitted)) +
  geom_bar() +
  theme_bw() +
  labs(x = "# Medications", y = "Patient Count", title = "Readmits by # Medications")

b5 <- ggplot(diabetictrain, aes(x = number_emergency, fill = readmitted)) +
  geom_bar() +
  theme_bw() +
  labs(x = "# Emergency Visits", y = "Patient Count", title = "Readmits by # Emergency Visits")

b6 <- ggplot(diabetictrain, aes(x = number_inpatient, fill = readmitted)) +
  geom_bar() +
  theme_bw() +
  labs(x = "# Inapatient Visits", y = "Patient Count", title = "Readmits by # Inpatient Visits")

b6 <- ggplot(diabetictrain, aes(x = number_diagnoses, fill = readmitted)) +
  geom_bar() +
  theme_bw() +
  labs(x = "# Diagnosis", y = "Patient Count", title = "Readmits by # Diagnoses")

multiplot(b1, b2, b3, b4, b5, b6, cols = 3)

```

```{r}
###RANDOM FOREST
#Train the data
bestmtry <- tuneRF(trainTransformed, trainTransformed$readmitted,
                   stepFactor = 1.2, improve = 0.01, trace = T, plot = T)
diabeticrf <- randomForest(readmitted ~ ., 
                           data=trainTransformed,
                           na.action = na.omit)
print(diabeticrf)

#Plot variables
plot(diabeticrf)
varImpPlot(diabeticrf)
diabeticrf$importance

#Predictions
pred1 <- predict(diabeticrf, newdata = testTransformed, type = "class")
pred1

#Check Accuracy via Confusion Matrix
confusionMatrix(table(pred1, testTransformed$readmitted))

#Plotting ROC curve and calculate AUC
probpred<- predict(diabeticrf, newdata = testTransformed, type = 'prob')
probpred
auc <- auc(testTransformed$readmitted,probpred[,2])
auc
plot(roc(testTransformed$readmitted,probpred[,2]))
```
CLASSIFICATION USING RANDOM FOREST

TUNERF
The purpose of using tuneRF function to provide an optimized number of random variables to allow for more variability and accuracy when Random Forest performs random selection for decision trees.In this case mtry = 6 was our result.

Parameters for tuneRF function:
trainTransformed: The data set in which we’ll be applying random forest
readmitted~.: This is my target variable in which we’re predicting readmission outcomes
stepFactor = 1.2: During every iteration, the factor will increase by 1.2 reach optimized # of variables. Every iteration, factor will increase by 1.2.
Improve 0.01: This factor will allow an end to the process. If there is improvement of 0.01 from previous iteration, it will continue. If not, this will stop with optimized # of variables.
Trace & Plot = T: This will provide visual results once random forest is performed

Parameters for Random Forest function:
Readmittied~.: I selected my class label “readmitted” as the outcome of all predictor variables (~.). trainTransformed: This is my training set data after it has been normalized and scaled. I
na.action: Omitted any NAs listed in my data set because Random Forest will not run with missing values

PROS & CONS For Random Forest
PROS
Flexible
Works well for classification and regression problems
Can handle heavier computations
Better accuracy/performance
Does not require data preparation
Avoids overfitting with the use of different decision trees
Feature selection
CON
Very time consuming
More computations
Less intuitive and difficult to comprehend large data

RANDOM FOREST VERSUS SVM
This data set contained >100k occurrences which Random Forest can handle. Random Forest is a powerful and universal machine learning tool that can be used for both categorical and quantitative data which this data set includes. Random forest will provide the probability of one class or another. One of bigger issues other algorithms have is overfitting. Random forest provides enough variability in trees, in which overfitting won’t be a problem. SVM was considered based on the fact the we’re trying to predict a binary classification, however, this isn’t recommended for large data sets like this diabetic data set. More preprocessing is required. One-hot encoding is a vigorous process especially with a data set that already has a large number of variables. Scaling would probably need to be completed as well.

METRICS CALCULATED
pred1   Yes    No
 Yes  6492  3804
 No   5910 10735
                                          
Accuracy : 0.6394          
95% CI : (0.6337, 0.6452)
No Information Rate : 0.5397          
 P-Value [Acc > NIR] : < 2.2e-16       
                                          
Kappa : 0.2651          
Mcnemar's Test P-Value : < 2.2e-16       
                                          
Sensitivity : 0.5235          
Specificity : 0.7384          
Pos Pred Value : 0.6305          
Neg Pred Value : 0.6449          
 Prevalence : 0.4603          
Detection Rate : 0.2410          
Detection Prevalence : 0.3822          
 Balanced Accuracy : 0.6309          
                                          
'Positive' Class : Yes    

SENSITIVITY, SPECIFICITY, & ACCURACY
Sensitivity: 0.52
Here, we ask when readmitted is actually set to “Yes”, how often does it predict “Yes”? (True Positive Rate). How
6492 / (6492+5910) = 0.52

Specificity: 0.73
Here, we ask when readmitted is actually set to “No”, how often does it predict “No”? (1 minus FP rate)
10735/(3804+10735) = .73

Accuracy: 0.64
Here, we ask overall, how often is the classifier correct?
(6492+10735)/(6492+5910+3804+10735) = 0.64

AUC: Area under the curve: 0.6923

Reference: https://www.youtube.com/watch?v=gmmV4drPTS4
Reference: https://www.quora.com/What-are-the-advantages-and-disadvantages-for-a-random-forest-algorithm 
Reference: https://datascience.stackexchange.com/questions/6838/when-to-use-random-forest-over-svm-and-vice-versa 

test
